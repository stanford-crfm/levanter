data:
  id: JeanKaddour/minipile
  cache_dir: "gs://levanter-data/tokenized/llama2_minipile/"
  tokenizer: "meta-llama/Llama-2-70b-hf"
model:
  type: llama
initialize_from_hf: true
use_hf_model_config: true

trainer:
  seed: 42
  checkpointer:
    keep:
      - every: 10
  tracker:
    type: wandb
    project: "levanter"
    tags: ["pile", "llama2"]

  mp: p=f32,c=bfloat16

  model_axis_size: 1
  per_device_eval_parallelism: -1
  max_eval_batches: 2

  train_batch_size: 256
  num_train_steps: 10000
  steps_per_eval: 10
optimizer:
  learning_rate: 1.2E-5
  weight_decay: 0.1
  min_lr_ratio: 0.1
